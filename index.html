<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8"/>
        <title>OnSurfacePrior</title>
        <link rel="stylesheet" href="./style.css">
        <script type="text/javascript" src="./gb3d_bundle.js"></script>
    </head>

    <body>
        <div class="container">
            <div class="paper-title">
                <div class="col">
                    <div class="row"> <h1 class="short-title"> OnSurfacePrior </h1> </div>
                    <div class="row"> <h3 class="long-title"> Reconstructing Surfaces for Sparse Point Clouds with On-Surface Priors </h3> </div>
                    <div class="row"> <p class="conference-label"> CVPR 2022 </p> </div>
                </div>
            </div>

            <div class="authors-list">
                <div class="row">
                    <div class="col">
                        <div class="row"> <p class="author-name">Baorui Ma</p> </div>
                        <div class="row"> <p class="affiliation">Tsinghua University</p> </div>
                    </div>
                    <div class="col">
                        <div class="row"> <p class="author-name"><a href="https://yushen-liu.github.io/">Yu-Shen Liu</a></p> </div>
                        <div class="row"> <p class="affiliation">Tsinghua University</p> </div>
                    </div>
                    <div class="col">
                        <div class="row"> <p class="author-name">Zhizhong Han</p> </div>
                        <div class="row"> <p class="affiliation">Wayne State University</p> </div>
                    </div>
                </div>
            </div>

            <div class="resource-link">
                <div class="row">
                    <div class="col">
                        <a href="https://github.com/mabaorui/OnSurfacePrior">
                            <img class="resource-icon" src="./images/code.png" alt="code icon">
                            <p class="resource-text">Code</p>
                        </a>
                    </div>
                    <div class="col">
                        <a href="https://yushen-liu.github.io/main/pdf/LiuYS_CVPR2022_OnSurfacePriors.pdf">
                            <img class="resource-icon" src="./images/paper.png" alt="paper icon">
                            <p class="resource-text">Paper</p>
                        </a>
                    </div>
                    <div class="col">
                        <a href="https://yushen-liu.github.io/main/pdf/LiuYS_CVPR2022_OnSurfacePriors-supp.pdf">
                            <img class="resource-icon" src="./images/supplement.png" alt="supplement icon">
                            <p class="resource-text">Supplement</p>
                        </a>
                    </div>
                </div>
            </div>

            <div class="intro-images">
                <div class="row">
                    <img class="abstract-img1" src="./images/overview.png" alt="abstract image"> 
                </div>
            </div>

            <section class="section">
                <div class="container is-max-desktop">
                      <!-- Paper video. -->
                      <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                          <h2 class="title is-3">Video</h2>
                          <div class="video">
                            <video width="100%" height="100%" controls autoplay loop>
                                <source src="./videos/CVPR2022_OnSurfacePriors.mp4" type="video/mp4"/>
                                Your browser does not support the video tag.
                            </video>
                        </div>
                        </div>
                      </div>
                      <!--/ Paper video. -->
                    
                  <br>
                  <!-- Abstract. -->
                  <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                      <h2 class="title is-3">Abstract</h2>
                      <div class="content has-text-justified">
                        <p>
                            It is an important task to reconstruct surfaces from 3D point clouds. Current methods are able to reconstruct surfaces by learning Signed Distance Functions (SDFs) from single point clouds without ground truth signed distances or point normals. However, they require the point clouds to be dense, which dramatically limits their performance in real applications. To resolve this issue, we propose to reconstruct highly accurate surfaces from sparse point clouds with an on-surface prior. We train a neural network to learn SDFs via projecting queries onto the surface represented by the sparse point cloud. Our key idea is to infer signed distances by pushing both the query projections to be on the surface and the projection distance to be the minimum. To achieve this, we train a neural network to capture the on-surface prior to determine whether a point is on a sparse point cloud or not, and then leverage it as a differentiable function to learn SDFs from unseen sparse point cloud. Our method can learn SDFs from a single sparse point cloud without ground truth signed distances or point normals. Our numerical evaluation under widely used benchmarks demonstrates that our method achieves state-of-the-art reconstruction accuracy, especially for sparse point clouds. Code and data are available at https://github.com/mabaorui/OnSurfacePrior.
                        </p>
                      </div>
                    </div>
                  </div>
                  <!--/ Abstract. -->
                </div>
              </section>

            <div class="view-3D">
                <p class="view-3D-title">
                    Results:
                </p>
                <div>
                    <h2>Visual comparison with IMLS [1] in unseen classes under ShapeNet.</h2>
                    
                    <table class="dataintable">
                    <tr>
                    <th style="width:33%;">Input points without normals</th>
                    <th style="width:33%;">IMLS</th>
                    <th style="width:33%;">Ours</th>
                    </tr>
                    
                    <tr>
                    <td>
                        <model-viewer alt="View reconstruction results in 3D" src="./objects/bathtub1_input.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                    </td>
                    <td>
                        <model-viewer alt="View reconstruction results in 3D" src="./objects/bathtub1_IMLS.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                    </td>
                    <td>
                        <model-viewer alt="View reconstruction results in 3D" src="./objects/bathtub1_ours.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                    </td>
                    </tr>

                    <tr>
                        <td>
                            <model-viewer alt="View reconstruction results in 3D" src="./objects/bathtub2_input.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                        </td>
                        <td>
                            <model-viewer alt="View reconstruction results in 3D" src="./objects/bathtub2_IMLS.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                        </td>
                        <td>
                            <model-viewer alt="View reconstruction results in 3D" src="./objects/bathtub2_ours.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                        </td>
                    </tr>

                    </table>
                </div>

                <div>
                    <h2>Visual comparison with COcc [2] under SceneNet.</h2>
                    
                    <table class="dataintable">
                    <tr>
                    <th style="width:33%;">Input points without normals</th>
                    <th style="width:33%;">COcc</th>
                    <th style="width:33%;">Ours</th>
                    </tr>
                    
                    <tr>
                    <td>
                        <model-viewer alt="View reconstruction results in 3D" src="./objects/bathroom_input.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                    </td>
                    <td>
                        <model-viewer alt="View reconstruction results in 3D" src="./objects/bathroom_cocc.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                    </td>
                    <td>
                        <model-viewer alt="View reconstruction results in 3D" src="./objects/bathroom_ours.glb" exposure="0.3" auto-rotate camera-controls></model-viewer>
                    </td>
                    </tr>

                    
                    </table>
                </div>
            </div>

            <div class="citation">
                <p class="citation-title">
                    Citation
                </p>
                <p class="citation-text">
                    @inproceedings{On-SurfacePriors,</br>
                        &ensp;&ensp;&ensp;&ensp;title={Reconstructing Surfaces for Sparse Point Clouds with On-Surface Priors},</br>
                        &ensp;&ensp;&ensp;&ensp;author={Baorui Ma and Yu-Shen Liu and Zhizhong Han},</br>
                        &ensp;&ensp;&ensp;&ensp;booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition},</br>
                        &ensp;&ensp;&ensp;&ensp;year={2022}</br>
                    }
                </p>
            </div>
            <div class="citation">
                <p class="citation-title">
                    Related Work
                </p>
                <p class="citation-text">
                    <strong>[1]</strong> Shi-Lin Liu, Hao-Xiang Guo, Hao Pan, PengshuaiWang, Xin Tong, and Yang Liu. Deep implicit moving least-squares functions for 3D reconstruction. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</br>
                    <strong>[2]</strong> Lars Mescheder Marc Pollefeys Andreas Geiger Songyou Peng, Michael Niemeyer. Convolutional occupancy networks. In European Conference on Computer Vision (ECCV), 2020.</br>
                    <strong>[3]</strong> Baorui Ma, Zhizhong Han, Yu-Shen Liu, Matthias Zwicker. Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces. International Conference on Machine Learning (ICML), 2021, PMLR 139: 7246-7257.</br>
                    <strong>[4]</strong> Baorui Ma, Yu-Shen Liu, Matthias Zwicker, Zhizhong Han. Surface Reconstruction from Point Clouds by Learning Predictive Context Priors. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</br>
                </p>
            </div>
        </div>
        <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    </body>

</html>
